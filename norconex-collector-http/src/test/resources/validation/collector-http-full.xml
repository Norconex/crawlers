<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE xml>
<!-- 
   Copyright 2017-2019 Norconex Inc.

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<!-- This is a config file with as many configuration options being set
     as possible, to test validation as much we can.
     -->
<httpcollector id="Test Collector HTTP Config">

  <!-- NEW: -->
  <workDir>/workdir</workDir>
  
<!-- DEPRECATED:
  <progressDir>/progress</progressDir>
  <logsDir>/logs</logsDir>
 -->
 
  <!-- NEW: -->
  <eventListeners>
    <listener class="com.norconex.collector.http.crawler.event.impl.URLStatusCrawlerEventListener">
      <statusCodes>404</statusCodes>
      <outputDir>/tmp/path</outputDir>
      <fileNamePrefix>broken-links</fileNamePrefix>
    </listener>
  </eventListeners>

  <crawlerDefaults>
    <startURLs stayOnDomain="true" includeSubdomains="true" stayOnPort="true" stayOnProtocol="true">
      <url>http://www.example.com</url>
      <url>http://www.sample.com</url>
      <urlsFile>/local/path/to/a/file/full/of/urls.txt</urlsFile>
      <sitemap>http://www.somewhere.com/sitemap.xml</sitemap>
      <provider class="com.norconex.collector.http.crawler.MockStartURLsProvider"/>
    </startURLs>
    <keepDownloads>true</keepDownloads>
    <keepOutOfScopeLinks>false</keepOutOfScopeLinks>
    <maxDepth>99</maxDepth>
    <numThreads>1</numThreads>
    <workDir>/tmp/111</workDir>
    <maxDocuments>111</maxDocuments>
    <orphansStrategy>PROCESS</orphansStrategy>
    
    <!-- NEW: -->
    <fetchHttpHead>true</fetchHttpHead>
    
    <!-- DEPRECATED:
    <crawlerListeners>
      <listener class="com.norconex.collector.http.crawler.event.impl.URLStatusCrawlerEventListener">
        <statusCodes>404</statusCodes>
        <outputDir>/tmp/path</outputDir>
        <fileNamePrefix>broken-links</fileNamePrefix>
      </listener>
    </crawlerListeners>
     -->
    
    <!-- DEPRECATED (part of httpFetchers):
    <userAgent>Please identify your Crawler</userAgent>
     -->
    <urlNormalizer disabled="false" class="com.norconex.collector.http.url.impl.GenericURLNormalizer">
      <normalizations>
        lowerCaseSchemeHost, upperCaseEscapeSequence, 
        decodeUnreservedCharacters, removeDefaultPort 
      </normalizations>
      <replacements>
        <replace><match>A</match><replacement>B</replacement></replace>
        <replace><match>C</match></replace>
      </replacements>
    </urlNormalizer>
    <delay class="com.norconex.collector.http.delay.impl.GenericDelayResolver"
          default="1s" ignoreRobotsCrawlDelay="true" scope="crawler" >
      <schedule dayOfWeek="from Monday to Friday"
          dayOfMonth="from 1 to 10" time="from 8:00 to 16:30">10s</schedule>
      <schedule dayOfWeek="from Saturday to Sunday"
          dayOfMonth="from 11 to 28" time="from 6:00 to 7:30">20000</schedule>
    </delay>    
    <dataStoreEngine class="com.norconex.collector.core.store.impl.nitrite.NitriteDataStoreEngine">
      <host>localhost</host>
      <port>1234</port>
      <dbname>dbName</dbname>
      <username>user</username>
      <password>pwd</password>
    </dataStoreEngine>
    
    <!-- DEPRECATED:
    <httpClientFactory class="com.norconex.collector.http.client.impl.GenericHttpClientFactory">
      ...
    </httpClientFactory>
    -->
    
    <!-- NEW: -->
    <httpFetchers maxRetries="5" retryDelay="10 seconds">
      <fetcher class="com.norconex.collector.http.fetch.impl.GenericHttpFetcher">
          <userAgent>Here we crawl!</userAgent>
          <cookiesDisabled>true</cookiesDisabled>
          <connectionTimeout>1</connectionTimeout>
          <socketTimeout>2 minutes</socketTimeout>
          <connectionRequestTimeout>3 min 30s</connectionRequestTimeout>
          <connectionCharset>US-ASCII</connectionCharset>
          <expectContinueEnabled>true</expectContinueEnabled>
          <maxRedirects>4</maxRedirects>
          <redirectURLProvider fallbackCharset="UTF-8"/>
          <localAddress>address</localAddress>
          <maxConnections>5</maxConnections>
          <maxConnectionsPerRoute>6</maxConnectionsPerRoute>
          <maxConnectionIdleTime>7</maxConnectionIdleTime>
          <maxConnectionInactiveTime>8</maxConnectionInactiveTime>
          <trustAllSSLCertificates>true</trustAllSSLCertificates>
          <sslProtocols>item1,item2</sslProtocols>
          <proxyHost>host</proxyHost>
          <proxyPort>9</proxyPort>
          <proxyRealm>realm</proxyRealm>
          <proxyScheme>scheme</proxyScheme>
          <proxyUsername>username</proxyUsername>
          <proxyPassword>pwd</proxyPassword>
          <proxyPasswordKey>key</proxyPasswordKey>
          <proxyPasswordKeySource>environment</proxyPasswordKeySource>
          <headers>
            <header name="head1"></header>
            <header name="head2">value2</header>
          </headers>
          <authMethod>digest</authMethod>
          <authUsername>user</authUsername>
          <authPassword>pass</authPassword>
          <authPasswordKey>thekey</authPasswordKey>
          <authPasswordKeySource>file</authPasswordKeySource>
          <authUsernameField>userfield</authUsernameField>
          <authPasswordField>pwdfield</authPasswordField>
          <authURL>authURL</authURL>
          <authFormParams>
            <param name="token1"></param>
            <param name="token2">somevalue2</param>
          </authFormParams>
          <authFormCharset>UTF-8</authFormCharset>
          <authHostname>authHost</authHostname>
          <authPort>9</authPort>
          <authRealm>authRealm</authRealm>
          <authWorkstation>authWorkstation</authWorkstation>
          <authDomain>authDomain</authDomain>
          <authPreemptive>true</authPreemptive>
          <validStatusCodes>200,201</validStatusCodes>
          <notFoundStatusCodes>404,401</notFoundStatusCodes>
          <headersPrefix>myprefix</headersPrefix>
          <detectContentType>true</detectContentType>
          <detectCharset>true</detectCharset>
      </fetcher>
    </httpFetchers>    
    
    <referenceFilters>
      <filter class="com.norconex.collector.core.filter.impl.ExtensionReferenceFilter"
          onMatch="exclude" caseSensitive="true">xml,pdf,doc</filter>
      <filter class="com.norconex.collector.core.filter.impl.RegexReferenceFilter"
          onMatch="exclude" caseSensitive="false">.*example.com.*</filter>
      <filter class="com.norconex.collector.http.filter.impl.SegmentCountURLFilter"
              onMatch="exclude" count="5" duplicate="false" separator="/" />
    </referenceFilters>    
    <robotsTxt ignore="false" class="com.norconex.collector.http.robot.impl.StandardRobotsTxtProvider"/>
    <sitemapResolverFactory ignore="false" lenient="true" 
        class="com.norconex.collector.http.sitemap.impl.StandardSitemapResolverFactory">
      <tempDir>/tmp/</tempDir>
      <path>/path1/</path>
      <path>/path2/</path>
    </sitemapResolverFactory>
    <!-- DEPRECATED:
    <redirectURLProvider class="com.norconex.collector.http.fetch.util.GenericRedirectURLProvider"
        fallbackCharset="UTF-8" />
     -->
    <recrawlableResolver class="com.norconex.collector.http.recrawl.impl.GenericRecrawlableResolver"
             sitemapSupport="last" >
         <minFrequency applyTo="reference" caseSensitive="false" value="always" >
             .*\.pdf
         </minFrequency>
         <minFrequency applyTo="contentType" caseSensitive="true" value="3000" >
             text/html
         </minFrequency>
    </recrawlableResolver>
    
    <!-- DEPRECATED:
    <metadataFetcher class="com.norconex.collector.http.fetch.impl.GenericMetadataFetcher" >
      <validStatusCodes>200,123</validStatusCodes>
      <notFoundStatusCodes>404,456</notFoundStatusCodes>
      <headersPrefix>prefix</headersPrefix>
    </metadataFetcher>
     -->
    <metadataFilters>
      <filter class="com.norconex.collector.core.filter.impl.ExtensionReferenceFilter"
          onMatch="exclude" caseSensitive="true">xml,pdf,doc</filter>
      <filter class="com.norconex.collector.core.filter.impl.RegexReferenceFilter"
          onMatch="exclude" caseSensitive="false">.*example.com.*</filter>
      <filter class="com.norconex.collector.core.filter.impl.RegexMetadataFilter"
          onMatch="include" caseSensitive="false" field="title">Blah.*</filter>
      <filter class="com.norconex.collector.http.filter.impl.SegmentCountURLFilter"
              onMatch="exclude" count="5" duplicate="false" separator="/" />
    </metadataFilters>
    <canonicalLinkDetector class="com.norconex.collector.http.url.impl.GenericCanonicalLinkDetector"
          ignore="true">
      <contentTypes>text/html</contentTypes>
    </canonicalLinkDetector>
    <metadataChecksummer 
        class="com.norconex.collector.http.checksum.impl.LastModifiedMetadataChecksummer"
        disabled="false" keep="true" targetField="myfield" />
        
    <!-- DEPRECATED:
    <documentFetcher class="com.norconex.collector.http.fetch.impl.GenericDocumentFetcher"
        detectContentType="true" detectCharset="true">
      <validStatusCodes>200,123</validStatusCodes>
      <notFoundStatusCodes>404,456</notFoundStatusCodes>
      <headersPrefix>prefix</headersPrefix>
    </documentFetcher>
     -->    
    <robotsMeta ignore="false" 
       class="com.norconex.collector.http.robot.impl.StandardRobotsMetaProvider">
       <headersPrefix>prefix</headersPrefix>
    </robotsMeta>
    <linkExtractors>
      <extractor class="com.norconex.collector.http.url.impl.GenericLinkExtractor"
          maxURLLength="999" ignoreNofollow="false" 
          commentsEnabled="true" charset="UTF-8" >
        <contentTypes>text/html</contentTypes>
        <schemes>https</schemes>
        <tags>
          <tag name="a" attribute="href" />
          <tag name="frame" attribute="src" />
          <tag name="iframe" attribute="src" />
          <tag name="img" attribute="src" />
          <tag name="meta" attribute="http-equiv" />
        </tags>
        <extractBetween caseSensitive="true">
          <start>start1</start><end>end1</end>
        </extractBetween>
        <extractBetween caseSensitive="false">
          <start>start2</start><end>end2</end>
        </extractBetween>
        <noExtractBetween caseSensitive="true">
          <start>nostart1</start><end>noend1</end>
        </noExtractBetween>
        <noExtractBetween caseSensitive="false">
          <start>nostart2</start><end>noend2</end>
        </noExtractBetween>
      </extractor>
      <extractor class="com.norconex.collector.http.url.impl.GenericLinkExtractor">
        <tags>
          <tag name="a" attribute="href" />
          <tag name="script" attribute="src" />
        </tags>
      </extractor>
      <extractor class="com.norconex.collector.http.url.impl.RegexLinkExtractor"
          maxURLLength="1234" charset="iso-8859-1">
        <applyToContentTypePattern>ct.*</applyToContentTypePattern>
        <applyToReferencePattern>ref.*</applyToReferencePattern>
        <linkExtractionPatterns>
          <pattern><match>\[(.*?)\]</match><replace>$1</replace></pattern>
          <pattern><match>http://.*?\.html</match></pattern>
        </linkExtractionPatterns>
      </extractor>
      <extractor class="com.norconex.collector.http.url.impl.XMLFeedLinkExtractor">
          <applyToContentTypePattern>.*</applyToContentTypePattern>
          <applyToReferencePattern>.*</applyToReferencePattern>
      </extractor>      
    </linkExtractors>
    <documentFilters>
      <filter class="com.norconex.collector.core.filter.impl.ExtensionReferenceFilter"
          onMatch="exclude" caseSensitive="true">xml,pdf,doc</filter>
      <filter class="com.norconex.collector.core.filter.impl.RegexReferenceFilter"
          onMatch="exclude" caseSensitive="false">.*example.com.*</filter>
      <filter class="com.norconex.collector.core.filter.impl.RegexMetadataFilter"
          onMatch="include" caseSensitive="false" field="title">Blah.*</filter>
      <filter class="com.norconex.collector.http.filter.impl.SegmentCountURLFilter"
              onMatch="exclude" count="5" duplicate="false" separator="/" />
    </documentFilters>
    <preImportProcessors>
      <processor class="com.norconex.collector.http.processor.impl.FeaturedImageProcessor">
         <pageContentTypePattern>text/html</pageContentTypePattern>
         <domSelector>dom dom</domSelector>
         <minDimensions>425x312</minDimensions>
         <largest>true</largest>
         <imageCacheSize>1234</imageCacheSize>
         <imageCacheDir>/some/path</imageCacheDir>
         <storage>url, inline</storage>
         <scaleQuality>medium</scaleQuality>
         <scaleDimensions>25</scaleDimensions>
         <scaleStretch>true</scaleStretch>
         <imageFormat>gif</imageFormat>
         <storageDiskDir structure="datetime">/some/other/path</storageDiskDir>
         <storageDiskField>diskField</storageDiskField>
         <storageInlineField>inlineField</storageInlineField>
         <storageUrlField>urlField</storageUrlField>
      </processor>      
    </preImportProcessors>

    <!-- Importer is purposely slim since the full config is tested in
         Importer project. -->
    <importer>
      <preParseHandlers>
        <!-- "transformer" DEPRECATED for "handler": -->
        <handler class="com.norconex.importer.handler.transformer.impl.ReplaceTransformer">
          <replace><fromValue>A</fromValue><toValue>B</toValue></replace>
        </handler>  
      </preParseHandlers>
      <postParseHandlers>
        <handler class="com.norconex.importer.handler.transformer.impl.ReplaceTransformer">
          <replace><fromValue>C</fromValue><toValue>D</toValue></replace>
        </handler>  
      </postParseHandlers>    
    </importer>

    <documentChecksummer 
        class="com.norconex.collector.core.checksum.impl.MD5DocumentChecksummer"
        disabled="false" keep="true" targetField="afield">
      <sourceFields>field1,field2</sourceFields>
    </documentChecksummer>
    <postImportProcessors>
      <processor class="com.norconex.collector.http.processor.impl.MockHttpDocumentProcessor"/>
    </postImportProcessors>    
    <spoiledReferenceStrategizer 
        class="com.norconex.collector.core.spoil.impl.GenericSpoiledReferenceStrategizer"
        fallbackStrategy="DELETE">
      <mapping state="NOT_FOUND" strategy="DELETE" />
      <mapping state="BAD_STATUS" strategy="DELETE" />
      <mapping state="ERROR" strategy="IGNORE" />
    </spoiledReferenceStrategizer>

    <committer class="com.norconex.committer.core.impl.FileSystemCommitter">
      <directory>/tmp/somepath</directory>
    </committer>

  </crawlerDefaults>
  
  <crawlers>
    <crawler id="myCrawler1">
      <numThreads>2</numThreads>
      <workDir>/tmp/222</workDir>
      <maxDocuments>222</maxDocuments>
      <orphansStrategy>DELETE</orphansStrategy>
    </crawler>
    <crawler id="myCrawler2">
      <numThreads>3</numThreads>
      <workDir>/tmp/333</workDir>
      <maxDocuments>333</maxDocuments>
      <orphansStrategy>IGNORE</orphansStrategy>
    </crawler>
  </crawlers>


</httpcollector>